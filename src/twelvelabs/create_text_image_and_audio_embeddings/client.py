# This file was auto-generated by Fern from our API Definition.

import typing
from ..core.client_wrapper import SyncClientWrapper
from .. import core
from ..core.request_options import RequestOptions
from ..types.embedding_response import EmbeddingResponse
from ..core.pydantic_utilities import parse_obj_as
from ..errors.bad_request_error import BadRequestError
from json.decoder import JSONDecodeError
from ..core.api_error import ApiError
from ..core.client_wrapper import AsyncClientWrapper

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class CreateTextImageAndAudioEmbeddingsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def create_text_image_audio_embedding(
        self,
        *,
        engine_name: str,
        text: typing.Optional[str] = OMIT,
        text_truncate: typing.Optional[str] = OMIT,
        image_url: typing.Optional[str] = OMIT,
        image_file: typing.Optional[core.File] = OMIT,
        audio_url: typing.Optional[str] = OMIT,
        audio_file: typing.Optional[core.File] = OMIT,
        audio_truncate: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EmbeddingResponse:
        """
        This method creates embedings for text, image, and audio.
        You can create multiple types of embeddings in a single API call.

        Before you create an embedding, ensure that the following prerequisites are met:

        - [Text embedding prerequisites](/docs/create-text-embeddings#prerequisites)
        - [Image embedding prerequisites](/create-image-embeddings#prerequisites)
        - [Audio embedding prerequisites](/create-audio-embeddings#prerequisites)

        **Common parameters**:
        For all types of embeddings, set the following parameter::

        - `engine_name`: Specify the name of the video understanding engine you want to use. Example: "Marengo-retrieval-2.6".

        **Text embeddings**:
        To create an embedding for text, provide these parameters:

        - `text`: The text for which to create an embedding.
        - (Optional) `text_truncate`: Specify how to truncate text that exceeds 77 tokens.

        **Image embeddings**:
        To create an embedding for an image, provide the image by using one of these parameters:

        - `image_url`: A publicly accessible URL of your image file.
        - `image_file`: A local image file.
          **NOTE**: If you specify both the `image_url` and `image_file` parameters in the same request, the `image_url` parameter takes precedence.

        **Audio embeddings**:
        To create an embedding for an audio file, provide the audio file using one of the following parameters:

        - `audio_url`: A publicly accessible URL of your audio file.
        - `audio_file`: A local audio file.
        - _(Optional)_ `audio_truncate`: Specify how to truncate the embeddings for audio files that exceed 10 seconds.
          **NOTE**: If you specify both the `audio_url` and `audio_file` parameters in the same request, the `audio_url` parameter takes precedence over `audio_file`.

        Parameters
        ----------
        engine_name : str
            The name of the engine you want to use. The following engines are available:
              - `Marengo-retrieval-2.6`


        text : typing.Optional[str]
            The text for which you wish to create an embedding.

            **NOTE**:
            Text embeddings are limited to 77 tokens. If the text exceeds this limit, the platform truncates it according to the value of the `text_truncate` parameter described below.

            **Example**: "Man with a dog crossing the street"


        text_truncate : typing.Optional[str]
            Specifies how the platform truncates text that exceeds 77 tokens to fit the maximum length allowed for an embedding.
            This parameter can take one of the following values:
            - `start`: The platform will truncate the start of the provided text.
            - `end`: The platform will truncate the end of the provided text.
            - `none`: The platform will return an error if the text is longer than the maximum token limit.
            **Default**: `end`


        image_url : typing.Optional[str]
            The publicly accessible URL of the image for which you wish to create an embedding. This parameter is required for image embeddings if `image_file` is not provided.


        image_file : typing.Optional[core.File]
            See core.File for more documentation

        audio_url : typing.Optional[str]
            The publicly accessible URL of the audio file for which you wish to creae an emebdding. This parameter is required for audio embeddings if `audio_file` is not provided.


        audio_file : typing.Optional[core.File]
            See core.File for more documentation

        audio_truncate : typing.Optional[str]
            Specifies how the platform truncates audio files that exceed 10 seconds to fit the maximum length allowed for an embedding.
            This parameter can take one of the following values:
            - `start`: The platform will truncate the start of the provided audio file.
            - `end`: The platform will truncate the end of the provided audio file.
            - `none`: The platform will return an error if the audio file is longer than the maximum limit.
            **Default**: `end`


        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EmbeddingResponse
            A text embedding has successfully been created.


        Examples
        --------
        from twelvelabs import TwelveLabs

        client = TwelveLabs(
            api_key="YOUR_API_KEY",
        )
        client.create_text_image_and_audio_embeddings.create_text_image_audio_embedding(
            engine_name="engine_name",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "embed-new",
            method="POST",
            data={
                "engine_name": engine_name,
                "text": text,
                "text_truncate": text_truncate,
                "image_url": image_url,
                "audio_url": audio_url,
                "audio_truncate": audio_truncate,
            },
            files={
                "image_file": image_file,
                "audio_file": audio_file,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EmbeddingResponse,
                    parse_obj_as(
                        type_=EmbeddingResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 400:
                raise BadRequestError(
                    typing.cast(
                        typing.Optional[typing.Any],
                        parse_obj_as(
                            type_=typing.Optional[typing.Any],  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncCreateTextImageAndAudioEmbeddingsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def create_text_image_audio_embedding(
        self,
        *,
        engine_name: str,
        text: typing.Optional[str] = OMIT,
        text_truncate: typing.Optional[str] = OMIT,
        image_url: typing.Optional[str] = OMIT,
        image_file: typing.Optional[core.File] = OMIT,
        audio_url: typing.Optional[str] = OMIT,
        audio_file: typing.Optional[core.File] = OMIT,
        audio_truncate: typing.Optional[str] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> EmbeddingResponse:
        """
        This method creates embedings for text, image, and audio.
        You can create multiple types of embeddings in a single API call.

        Before you create an embedding, ensure that the following prerequisites are met:

        - [Text embedding prerequisites](/docs/create-text-embeddings#prerequisites)
        - [Image embedding prerequisites](/create-image-embeddings#prerequisites)
        - [Audio embedding prerequisites](/create-audio-embeddings#prerequisites)

        **Common parameters**:
        For all types of embeddings, set the following parameter::

        - `engine_name`: Specify the name of the video understanding engine you want to use. Example: "Marengo-retrieval-2.6".

        **Text embeddings**:
        To create an embedding for text, provide these parameters:

        - `text`: The text for which to create an embedding.
        - (Optional) `text_truncate`: Specify how to truncate text that exceeds 77 tokens.

        **Image embeddings**:
        To create an embedding for an image, provide the image by using one of these parameters:

        - `image_url`: A publicly accessible URL of your image file.
        - `image_file`: A local image file.
          **NOTE**: If you specify both the `image_url` and `image_file` parameters in the same request, the `image_url` parameter takes precedence.

        **Audio embeddings**:
        To create an embedding for an audio file, provide the audio file using one of the following parameters:

        - `audio_url`: A publicly accessible URL of your audio file.
        - `audio_file`: A local audio file.
        - _(Optional)_ `audio_truncate`: Specify how to truncate the embeddings for audio files that exceed 10 seconds.
          **NOTE**: If you specify both the `audio_url` and `audio_file` parameters in the same request, the `audio_url` parameter takes precedence over `audio_file`.

        Parameters
        ----------
        engine_name : str
            The name of the engine you want to use. The following engines are available:
              - `Marengo-retrieval-2.6`


        text : typing.Optional[str]
            The text for which you wish to create an embedding.

            **NOTE**:
            Text embeddings are limited to 77 tokens. If the text exceeds this limit, the platform truncates it according to the value of the `text_truncate` parameter described below.

            **Example**: "Man with a dog crossing the street"


        text_truncate : typing.Optional[str]
            Specifies how the platform truncates text that exceeds 77 tokens to fit the maximum length allowed for an embedding.
            This parameter can take one of the following values:
            - `start`: The platform will truncate the start of the provided text.
            - `end`: The platform will truncate the end of the provided text.
            - `none`: The platform will return an error if the text is longer than the maximum token limit.
            **Default**: `end`


        image_url : typing.Optional[str]
            The publicly accessible URL of the image for which you wish to create an embedding. This parameter is required for image embeddings if `image_file` is not provided.


        image_file : typing.Optional[core.File]
            See core.File for more documentation

        audio_url : typing.Optional[str]
            The publicly accessible URL of the audio file for which you wish to creae an emebdding. This parameter is required for audio embeddings if `audio_file` is not provided.


        audio_file : typing.Optional[core.File]
            See core.File for more documentation

        audio_truncate : typing.Optional[str]
            Specifies how the platform truncates audio files that exceed 10 seconds to fit the maximum length allowed for an embedding.
            This parameter can take one of the following values:
            - `start`: The platform will truncate the start of the provided audio file.
            - `end`: The platform will truncate the end of the provided audio file.
            - `none`: The platform will return an error if the audio file is longer than the maximum limit.
            **Default**: `end`


        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        EmbeddingResponse
            A text embedding has successfully been created.


        Examples
        --------
        import asyncio

        from twelvelabs import AsyncTwelveLabs

        client = AsyncTwelveLabs(
            api_key="YOUR_API_KEY",
        )


        async def main() -> None:
            await client.create_text_image_and_audio_embeddings.create_text_image_audio_embedding(
                engine_name="engine_name",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "embed-new",
            method="POST",
            data={
                "engine_name": engine_name,
                "text": text,
                "text_truncate": text_truncate,
                "image_url": image_url,
                "audio_url": audio_url,
                "audio_truncate": audio_truncate,
            },
            files={
                "image_file": image_file,
                "audio_file": audio_file,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    EmbeddingResponse,
                    parse_obj_as(
                        type_=EmbeddingResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 400:
                raise BadRequestError(
                    typing.cast(
                        typing.Optional[typing.Any],
                        parse_obj_as(
                            type_=typing.Optional[typing.Any],  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
